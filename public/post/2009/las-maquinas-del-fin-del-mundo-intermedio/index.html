<!DOCTYPE html>
<html lang="es-cl" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Las máquinas del fin del mundo (intermedio) | La Naturaleza del Software</title>
<link rel="icon" href="/favicon.svg" sizes="any" type="image/svg+xml" /><meta property="og:url" content="http://localhost:1313/post/2009/las-maquinas-del-fin-del-mundo-intermedio/">
  <meta property="og:site_name" content="La Naturaleza del Software">
  <meta property="og:title" content="Las máquinas del fin del mundo (intermedio)">
  <meta property="og:description" content="Ya hemos visto una posición, en uno de los extremos, sobre que hacer ante las amenazas de la tecnología para nuestra sociedad.
En 2006 escribí este artículo, que he decidido retocar y adaptar a mi serie actual sobre los desafíos que nos impone la tecnología, creo que es apropiado publicarlo en este momento, como una suerte de puente hacia la otra propuesta extrema, sobre que hacer ante estos escenarios, en que podemos ser sobrepasados por la tecnología.">
  <meta property="og:locale" content="es_cl">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2009-05-26T20:53:24+00:00">
    <meta property="article:modified_time" content="2009-05-26T20:53:24+00:00">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Las máquinas del fin del mundo (intermedio)">
  <meta name="twitter:description" content="Ya hemos visto una posición, en uno de los extremos, sobre que hacer ante las amenazas de la tecnología para nuestra sociedad.
En 2006 escribí este artículo, que he decidido retocar y adaptar a mi serie actual sobre los desafíos que nos impone la tecnología, creo que es apropiado publicarlo en este momento, como una suerte de puente hacia la otra propuesta extrema, sobre que hacer ante estos escenarios, en que podemos ser sobrepasados por la tecnología.">

    <link rel="stylesheet" href="/css/root.css">
    <link rel="stylesheet" href="/css/bundle.css">

      <script src="/js/bundle.js"></script><script defer src="/js/search/flexsearch.compact.64594b125f7b78bdf4fa8316955922bbebb1cd6baef3f16654bfca20309f18f8.js" integrity="sha256-ZFlLEl97eL30&#43;oMWlVkiu&#43;uxzWuu8/FmVL/KIDCfGPg="></script>
<script defer src="/js/search/search.1d980f84df11f3eb7c8c5f17f541d49a0611608df179dd74fa7f06225eb56ace.js" integrity="sha256-HZgPhN8R8&#43;t8jF8X9UHUmgYRYI3xed10&#43;n8GIl61as4="></script>

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Bricolage+Grotesque:opsz,wght@12..96,200..800&family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap" rel="stylesheet">

</head>
<body class="notransition">
  <div id="container">
    <header id="main-header"><div role="navigation" aria-label="Main">
  <div class="nav-left">
    <a href="http://localhost:1313/" style="color: inherit;">La Naturaleza del Software</a>
  </div>
  <div class="nav-right">
    <div style="position:absolute;width:0px;height:0px;">
      <div id="nav-dropdown-menu" class="hidden" href="#">
    <div class="nav-item">
      <a
      >Posts</a>
    </div>
</div>
    </div>
    <a id="nav-dropdown-button" href="#"><svg width="20px" height="20px" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M4 6H20M4 12H20M4 18H20" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
</svg>
</a>
    <div id="nav-menu">
    <div class="nav-item">
      <a
      >Posts</a>
    </div>
</div>
    <a id="theme-switcher" href="#">
<svg class="light-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M12 3V4M12 20V21M4 12H3M6.31412 6.31412L5.5 5.5M17.6859 6.31412L18.5 5.5M6.31412 17.69L5.5 18.5001M17.6859 17.69L18.5 18.5001M21 12H20M16 12C16 14.2091 14.2091 16 12 16C9.79086 16 8 14.2091 8 12C8 9.79086 9.79086 8 12 8C14.2091 8 16 9.79086 16 12Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
</svg>

<svg class="dark-icon" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M3.32031 11.6835C3.32031 16.6541 7.34975 20.6835 12.3203 20.6835C16.1075 20.6835 19.3483 18.3443 20.6768 15.032C19.6402 15.4486 18.5059 15.6834 17.3203 15.6834C12.3497 15.6834 8.32031 11.654 8.32031 6.68342C8.32031 5.50338 8.55165 4.36259 8.96453 3.32996C5.65605 4.66028 3.32031 7.89912 3.32031 11.6835Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
</svg>
</a>
  </div>
</div>
</header>
    <div class="flex grow">
      <div id="main-pane">
        <main id="main-content"><div class="single-header">
<ol class="breadcrumbs" itemscope itemtype="https://schema.org/BreadcrumbList">
    <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
      <a itemprop="item" href="http://localhost:1313/">
        <span itemprop="name">Home</span>
      </a>
      <meta itemprop="position" content='1' />
    </li>
    <span>&nbsp»&nbsp</span>
    <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
      <a itemprop="item" href="http://localhost:1313/post/">
        <span itemprop="name">Posts</span>
      </a>
      <meta itemprop="position" content='2' />
    </li>
    <span>&nbsp»&nbsp</span>
</ol>
<h1>Las máquinas del fin del mundo (intermedio)</h1><time class="dim" datetime="2009-05-26T20:53:24&#43;00:00">May 26, 2009</time></div>
  <section class="page-section"><p>Ya hemos visto <a href="http://www.lnds.net/2009/05/el-desafio-del-nuevo-ludita.html">una posición</a>, en uno de los extremos, sobre que hacer ante las amenazas de la tecnología para nuestra sociedad.</p>
<p>En 2006 escribí este artículo, que he decidido retocar y adaptar a mi serie actual sobre los desafíos que nos impone la tecnología, creo que es apropiado publicarlo en este momento, como una suerte de puente hacia la otra propuesta extrema, sobre que hacer ante estos escenarios, en que podemos ser sobrepasados por la tecnología.</p>
<p>Las máquinas del fin del mundo</p>
<p>Leí con asombro un post de mi hermano, sobre una cadena que <a href="http://www.ricardodiaz.org/archives/2006/04/fin.html">anuncia el fin del mundo para el 6 de junio de este año (6/6/6)</a> <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>.</p>
<p>Aparte de ser una interesante coincidencia numérica, ¿qué razones hay para pensar de que el mundo debe acabar?</p>
<h2 id="el-fin-por-culpa-de-la-tecnología">El fin por culpa de la tecnología</h2>
<p>La verdad es que el fin del mundo ha sido anunciado muchas veces, y no sólo por fanáticos religiosos.</p>
<p><img src="atomic_bomb_explosion_2.jpg" alt="atomic_bomb_explosion_2.jpg"></p>
<p>Las visiones apocalípticas normalmente anuncian todo tipo de cataclismos, pero, como sería de esperar, en el último tiempo, se han agregado otras causas para el fin del mundo, muchas consecuencia de nuestro abuso de la tecnología:</p>
<ul>
<li>El fin del mundo por el uso de armas bioquímicas</li>
<li>Guerra Nuclear total</li>
<li>La explosión de plantas nucleares</li>
<li><a href="http://www.lnds.net/2008/09/buuum.html">Una super máquina que crea un vórtice</a>, o un agujero negro</li>
<li>El calentamiento global y una nueva era glacial</li>
<li>El surgimiento de inteligencias artificiales que destruyen a su creador</li>
</ul>
<p>Esta última &ldquo;amenaza&rdquo; es la que me interesa explorar ahora, porque tiene que ver con temas que domino más.</p>
<h2 id="el-miedo-a-la-inteligencia-artificial">El miedo a la inteligencia artificial</h2>
<p><img src="hal9000.jpg" alt="hal.jpg"></p>
<p>El temor al alzamiento de las máquinas ha sido discutido en taquilleras películas como Terminator y Matrix, y de una forma más elegante en &ldquo;2001 Odisea Espacial&rdquo;.</p>
<p>Cuando se habla de esta visión de la máquina que se alza contra su creador, muchos comparan con el <a href="http://www.literature.org/authors/shelley-mary/frankenstein/">Frankenstein</a>, de Mary Shelley. En realidad no es lo mismo, pues la &ldquo;criatura&rdquo; es un humano vuelt
o a la vida (bueno, un cuarpo humano reanimado, construido a partir de partes de muchos cadaveres).</p>
<p>En Matrix no sabemos cómo son las &ldquo;máquinas&rdquo;, vemos robots en forma de calamares, pero son sólo &ldquo;trajes&rdquo;, para acomodar inteligencias artificiales. Las inteligencias artificiales viven en la matrix, un mundo virtual, que tiene un soporte físico (hardware), alimentado por la energía bioquímica de millones de seres humanos.</p>
<p>En Terminator la idea es similar, una inteligencia artificial surge desde una red militar (skynet), y esta intelgencia decide destruir al hombre, para eso se sirve de robots, conocidos como exterminadores, pero nuevamente, las IA están en otra parte.</p>
<p>John Connor sabe que debe destruir Skynet antes que se forme, porque probablemente el acceso a Skynet es imposible. Neo se dirige hacia una suerte de nucleo de la Matrix, porque sabe que aunque maten a todos los robots calamares estos no son el problema.</p>
<p><img src="hyperion_early_sm.jpg" alt="hyperion_early_sm.jpg"></p>
<p>La brillante saga de ciencia ficción Hyperión, de Dan Simmons, nos muestra una guerra entre las IA y las personas, con una interesante variante, las IA han decidido sacrificarse a si mismas para crear IA más evolucionadas (¿seríamos capaces de sacrificarnos por la especie que nos suceda?).</p>
<p>En todos estos casos, ls enemigos, no vistos, son Inteligencias Artificiales que viven, flotan, por decirlo de alguna manera, en una red, o soporte físico. Son programas, algoritmos, heurísticas, en cierta manera, pero con capacidad de aprender y manipular su entorno con el fin de protegerse, por ejemplo, construyendo robots.</p>
<p>No son los robots los peligrosos, estos son herramientas, son las inteligencias artificiales las que comandan y las peligrosas.</p>
<p>Pero, por su naturaleza, las IA son escurridizas. En 2001, HAL es eliminado, pues tiene un soporte físico de fácil acceso. Pero en Matrix y Terminator, eso no es posible, y los heroes de esa sagas, deben tratar de evitar que surjan, en el caso de Terminator, o atacar el núcleo donde se encuentran, como en Matrix.</p>
<p>Sin embargo, la estrategia de John Connor es más astuta que la de Neo, porque John Connor quiere evitar que Skynet llegue a existir, pero se produce una interesante paradoja, que si John Connor destruye Skynet, el dejará de existir. En el caso de Matrix, sabemos que Neo no puede destruir a las IA, que la lucha es eterna y se repetirá por siempre, porque Neo en cierta manera es un mecanismo de la misma matrix para reorganizarse.</p>
<p>Quizás por eso Matrix como trilogía decepciona tanto. Porque esperabamos un desenlace más emocionante, pero en realidad nos llevan a un final decepcionante, en que las IA ganan. Pero también, nos queda claro, que en cierta manera, la matrix sigue dependiendo de humanos libres, una élite acaso, que viven en Zión.</p>
<p>Hemos visto, que sólo en 2001 el héroe logra eliminar la amenaza de la IA. HAL falla porque es incapaz en protegerse a si mismo.</p>
<h2 id="vida-artificial">Vida Artificial</h2>
<p>Actualmente se postula que  antes de construir una IA, debemos contruir niveles inferiores de inteligencia. Estos rdimentos de inteligencia artificial ya están disponibles, <a href="http://www.lnds.net/2009/03/el-sueno-de-las-ovejas-electricas.html">incluso al alcance de cualquiera de nosotros</a>. Estos rudimentos, constituyen los &ldquo;instintos&rdquo; de las IA.<br>
Sin esos instintos básicos, que le permitan a la IA desarrollarse, no será posible que esta llegue a ser conciente.</p>
<p>Una Inteligencia Artificial debería</p>
<ol>
<li>Preservarse</li>
<li>Reproducirse</li>
<li>Evolucionar</li>
</ol>
<p>Estos tres requisitos básicos son las bases de la denominada <a href="http://vidaartificial.com/index.php?title=Vida_Artificial">tesis fuerte de la vida artificia</a>l, en esencia esta dice que una vida es un modelo operacional, y si satisface las tres operaciones mencionadas, entonces da lo mismo el soporte físico de la vida.</p>
<p>La satisfacción de estas tres necesidades de las IAs son las que justificarían su hostilidad hacia nosotros. Efectivamente, si hacemos precaria su preservación, si tienen que competir con nosotros por los recursos, o somos un estorbo dentro de su evolución, las IAs pueden volverse contra sus creadores.</p>
<p>¿Dónde surgirá la Inteligencia Artificial?</p>
<p>Lo interesante, es saber si las inteligencias artificiales son capaces de desarrollarse fuera de su soporte físico, o antes de llegar a tenerlo, es decir, <a href="http://www.lnds.net/2008/12/y-si-las-inteligencias-artificiales-ya-e.html">¿pueden las IA surgir dentro de la red?</a>.</p>
<p>En Terminator, lo primero que se desarrolla es Skynet, una red informática, que empieza a controlar las factorías necesarias para desarrollar las armas y robots exterminadores.</p>
<p>Entonces, además de preocuparnos del mundo industrial, y de la amenazas de las máquinas, que principalmente son amenazas ambientales, es interesante concentrarse en  entender las amenazas que representan las tecnologías de la información, es decir, la amenaza de que se desarrolle una IA hostil.</p>
<p>Consideren el siguiente fragmento:</p>
<blockquote>
<p>&ldquo;¿Saben lo que es barato en el siglo 21? El tiempo de computación. ¿Saben lo que es caro? El juicio humano. Ambos no son intercambiables. Los humanos son buenos entendiendo cosas, los computadores son buenos contando cosas, pero los humanos apestan al contar, y os computadores apestan al entender.&rdquo;</p></blockquote>
<blockquote>
<p>&ldquo;¿Conocen los algoritmos genéticos? Tomen cualquier problema y generen 10 billones de pogramas de computador al azar y póngalos a resolver el problema. Tomen el 10% de los que lo hacen mejor, usen variantes al azar de ellos y repítanlos otras 10 billones de veces. Repítanlo 10 billones de veces más, y vuelvan en un día o dos, y descubrirán que el computador ha &ldquo;evolucionado&rdquo; a una extraña y bizarra respuesta que a ningún humano jamás se le habría ocurrido.&rdquo;</p>
<p>&ldquo;Ningún humano va a lograr escribir el código para una Inteligencia Artificial (IA). La inteligencia es una propiedad emergente de factores evolutivos, no de la planificación central. Es anarquía, no estalinismo. ¿Lo entienden?&rdquo;<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p></blockquote>
<p>¿Que tal si el surgimiento de la inteligencia artificial es algo inevitable, y eso hace que tengamos que empezar a aceptar que tendremos que lidiar con seres potencialmente superiores a nosotros?</p>
<p>Hay una propuesta extrema, que nos dice lo que debemos hacer en este caso, y que al contrario de lo propuesto por los neoluditas, y los que llaman a destruir, o abandonar la tecnología, toma un camino radicalmente opuesto, y es el que vamos a explorar en el siguiente post.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>La primera parte de este post fue escrita en abril de 2006, bajo el título de <a href="/2006/04/las-maquinas-del-fin-del-mundo.html">Las máquinas del fin del mundo</a>.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Cory Doctorow, &ldquo;Pester Power&rdquo;, relato publicado en Communications of ACM, diciembre 2008.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
</section></main>
        <footer id="main-footer"><div class="footer">
  <a href="#">Scroll to Top</a>
  <div class="footer-copyright">
    <div class="dim">© 2025 </div>
    <div>Made with ❤️ and powered by <a href="https://github.com/math-queiroz/rusty-typewriter" target="_blank">Rusty Typewriter</a> theme for <a href="https://gohugo.io/" target="_blank">Hugo</a></div>
  </div>
</div>
</footer>
      </div><aside id="side-pane" class="side-sticky"><div class="side-details">
    <span>1348 words</span>
    <span>8 - 10 minutes read</span><div class="side-details-taxonomy">
        <small>categories: 
          <span class="details-taxonomy"><a href="http://localhost:1313/categories/general">General</a></span><span class="details-taxonomy"><a href="http://localhost:1313/categories/paradigmas">Paradigmas</a></span></small>
      </div></div><h3>Table Of Contents</h3><nav id="TableOfContents">
  <ul>
    <li><a href="#el-fin-por-culpa-de-la-tecnología">El fin por culpa de la tecnología</a></li>
    <li><a href="#el-miedo-a-la-inteligencia-artificial">El miedo a la inteligencia artificial</a></li>
    <li><a href="#vida-artificial">Vida Artificial</a></li>
  </ul>
</nav><h3>Attachments</h3>
    <ul><li><a href="http://localhost:1313/post/2009/las-maquinas-del-fin-del-mundo-intermedio/atomic_bomb_explosion_2.jpg">atomic_bomb_explosion_2.jpg</a></li><li><a href="http://localhost:1313/post/2009/las-maquinas-del-fin-del-mundo-intermedio/hal9000.jpg">hal9000.jpg</a></li><li><a href="http://localhost:1313/post/2009/las-maquinas-del-fin-del-mundo-intermedio/hyperion_early_sm.jpg">hyperion_early_sm.jpg</a></li></ul></aside></div>
  </div>
</body>
</html>
